{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837a7c5a",
   "metadata": {},
   "source": [
    "# The environmental impact of data science\n",
    "\n",
    "## Resources for training AI models\n",
    "\n",
    "Artificial intelligence models require a large number of iterations to adjust their parameters and improve their performance. Datasets used to train these models are often very large, which implies substantial computation times. For example, training an image recognition model can require millions of images and tens or even hundreds of hours of computation on powerful processors.\n",
    "\n",
    "This demand on computing resources has a significant environmental impact as producing energy has a big environmental impact. What's more, the energy and water requirements for cooling IT equipment and data centers also increase the environmental impact.\n",
    "\n",
    "## GPU usage and environmental impact\n",
    "\n",
    "Graphics processing units (GPUs) have become indispensable for training deep learning models. GPUs generally consume more energy than conventional processors (CPUs) due to their architecture and operation. What's more, the use of these components generates large amounts of heat, necessitating water and energy-hungry cooling systems. For example, 1 kWh used in AWS data centers needs in [average 0.19 L](https://sustainability.aboutamazon.com/natural-resources/water) to cool the equipment.\n",
    "\n",
    "The environmental impact of GPU use is also reflected in the production and end-of-life of these components. The manufacture of GPUs requires the extraction and processing of rare and precious raw materials which has a significant ecological impact. What's more, the limited lifespan of GPUs and their frequent renewal generate electronic waste that is difficult to recycle. \n",
    "\n",
    "For example the manufacture of an [NVIDIA A100 GPU](https://dl.acm.org/doi/pdf/10.1145/3581784.3607035) is estimated to emit up to 25 kg of CO2e, and the manufacture of a [CPU](https://api.boavizta.org/docs#/component/cpu_impact_bottom_up_v1_component_cpu_get) is estimated to emit 19 kg CO2e (between 10 to 80)\n",
    "\n",
    "To compare:\n",
    "- [1 HP ProBook laptop manufacturing](https://h20195.www2.hp.com/v2/GetDocument.aspx?docname=c08546039) emit 112.5 kg of CO2e, \n",
    "- [3 000 km of car driving](https://impactco2.fr/outils/transport) emit 155 kg CO2e, \n",
    "- [1 hot shower in France](https://borisruf.github.io/carbon-footprint-modeling-tool/?id=scenario-1hot-shower) emit 162 g CO2e.\n",
    "- [1 kg of chicken meat produced](https://openknowledge.fao.org/server/api/core/bitstreams/121cc613-3d0f-431c-b083-cc2031dd8826/content) emit 1 kg CO2e\n",
    "- [1 kg of beef meat produced](https://openknowledge.fao.org/server/api/core/bitstreams/121cc613-3d0f-431c-b083-cc2031dd8826/content) emit 30 kg CO2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd31764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Computer vision\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Energy consumption\n",
    "from codecarbon import OfflineEmissionsTracker\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51ee7f",
   "metadata": {},
   "source": [
    "# First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def while_loop(n):\n",
    "    i = 0\n",
    "    s = 0\n",
    "    while i < n:\n",
    "        s += 1\n",
    "        i += 1\n",
    "    return s\n",
    "    \n",
    "def for_loop(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b88771",
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = 100000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773a2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.278241395950317 s\n"
     ]
    }
   ],
   "source": [
    "start_time_while = time.time()\n",
    "\n",
    "while_loop(numb)\n",
    "\n",
    "end_time_while = time.time()\n",
    "time_while = end_time_while - start_time_while\n",
    "print(f\"{time_while} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f17efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.628531694412231 s\n"
     ]
    }
   ],
   "source": [
    "start_time_for = time.time()\n",
    "\n",
    "for_loop(numb)\n",
    "\n",
    "end_time_for = time.time()\n",
    "time_for = end_time_for - start_time_for\n",
    "print(f\"{time_for} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c4cae",
   "metadata": {},
   "source": [
    "A for loop may be more optimized and streamlined for repetitive tasks with a known number of iterations, allowing for better resource management and potentially lower power consumption. While loops, on the other hand, may require additional instructions to evaluate the loop condition repeatedly, potentially resulting in higher power usage.\n",
    "\n",
    "# Carbon emissions of locally executed software code\n",
    "The Python package CodeCarbon is designed to measure the carbon footprint of executing code on a __local__ device. Check out the [documentation](https://mlco2.github.io/codecarbon/) for more details.\n",
    "\n",
    "### First steps with CodeCarbon\n",
    "Let's start with installing the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f75c3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import OfflineEmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011880ce",
   "metadata": {},
   "source": [
    "Start the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e7e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:34:01] offline tracker init\n",
      "[codecarbon INFO @ 17:34:01] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:34:01] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:34:01] No GPU found.\n",
      "[codecarbon INFO @ 17:34:01] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:34:01] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 17:34:06] CPU Model on constant consumption mode: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n",
      "[codecarbon INFO @ 17:34:06] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:34:06]   Platform system: Windows-10-10.0.19045-SP0\n",
      "[codecarbon INFO @ 17:34:06]   Python version: 3.11.5\n",
      "[codecarbon INFO @ 17:34:06]   CodeCarbon version: 2.3.4\n",
      "[codecarbon INFO @ 17:34:06]   Available RAM : 15.816 GB\n",
      "[codecarbon INFO @ 17:34:06]   CPU count: 8\n",
      "[codecarbon INFO @ 17:34:06]   CPU model: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n",
      "[codecarbon INFO @ 17:34:06]   GPU count: None\n",
      "[codecarbon INFO @ 17:34:06]   GPU model: None\n"
     ]
    }
   ],
   "source": [
    "tracker1 = OfflineEmissionsTracker(country_iso_code='IRL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01bceac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:34:21] Energy consumed for RAM : 0.000025 kWh. RAM Power : 5.930863380432129 W\n",
      "[codecarbon INFO @ 17:34:21] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 17:34:21] 0.000056 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 17:34:26] Energy consumed for RAM : 0.000033 kWh. RAM Power : 5.930863380432129 W\n",
      "[codecarbon INFO @ 17:34:26] Energy consumed for all CPUs : 0.000042 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 17:34:26] 0.000075 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n",
      "Training time: 20.11 seconds\n",
      "GHG emissions: 2.73e-05 kg CO2e\n",
      "Electricity: 7.5e-05 kWh\n"
     ]
    }
   ],
   "source": [
    "tracker1.start()\n",
    "\n",
    "print(while_loop(numb))\n",
    "\n",
    "tracker1.stop()\n",
    "print(f\"Training time: {tracker1.final_emissions_data.duration:.2f} seconds\")\n",
    "print(f\"GHG emissions: {np.format_float_scientific(tracker1.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "print(f\"Electricity: {np.format_float_scientific(tracker1.final_emissions_data.energy_consumed, precision=2)} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a71ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:34:26] offline tracker init\n",
      "[codecarbon INFO @ 17:34:26] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:34:26] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:34:26] No GPU found.\n",
      "[codecarbon INFO @ 17:34:26] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:34:26] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 17:34:30] CPU Model on constant consumption mode: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n",
      "[codecarbon INFO @ 17:34:30] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:34:30]   Platform system: Windows-10-10.0.19045-SP0\n",
      "[codecarbon INFO @ 17:34:30]   Python version: 3.11.5\n",
      "[codecarbon INFO @ 17:34:30]   CodeCarbon version: 2.3.4\n",
      "[codecarbon INFO @ 17:34:30]   Available RAM : 15.816 GB\n",
      "[codecarbon INFO @ 17:34:30]   CPU count: 8\n",
      "[codecarbon INFO @ 17:34:30]   CPU model: Intel(R) Core(TM) i7-8650U CPU @ 1.90GHz\n",
      "[codecarbon INFO @ 17:34:30]   GPU count: None\n",
      "[codecarbon INFO @ 17:34:30]   GPU model: None\n",
      "[codecarbon INFO @ 17:34:40] Energy consumed for RAM : 0.000016 kWh. RAM Power : 5.930863380432129 W\n",
      "[codecarbon INFO @ 17:34:40] Energy consumed for all CPUs : 0.000021 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 17:34:40] 0.000037 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n",
      "Training time: 9.95 seconds\n",
      "GHG emissions: 1.35e-05 kg CO2e\n",
      "Electricity: 3.71e-05 kWh\n"
     ]
    }
   ],
   "source": [
    "tracker2 = OfflineEmissionsTracker(country_iso_code='IRL')\n",
    "\n",
    "tracker2.start()\n",
    "\n",
    "print(for_loop(numb))\n",
    "\n",
    "tracker2.stop()\n",
    "print(f\"Training time: {tracker2.final_emissions_data.duration:.2f} seconds\")\n",
    "print(f\"GHG emissions: {np.format_float_scientific(tracker2.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "print(f\"Electricity: {np.format_float_scientific(tracker2.final_emissions_data.energy_consumed, precision=2)} kWh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f6a87",
   "metadata": {},
   "source": [
    "# Create python decorator with CodeCarbon to assess any function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f4fc3",
   "metadata": {},
   "source": [
    "### CodeCarbon parameters\n",
    "**tracking_mode**: machine (default): entire machine ; process: try to isolate the process\n",
    "\n",
    "**pue**: 1 (default) ; Old data-centers have a PUE up to 2.2, where new green one could be as low as 1.1.  \n",
    "Power usage effectiveness (PUE) is a metric used to measure the energy efficiency of a computer data center. It is the ratio of how much energy is used by the computing equipment in contrast to cooling and other overhead that supports the equipment.\n",
    "\n",
    "**gpu_ids**: None (default) ; User-specified known GPU ids to track.\n",
    "\n",
    "**measure_power_secs**: 15 (default) ; Interval (in seconds) to measure hardware power usage. The smaller it is, the more precise the measure is, but the more resources it requires =(\n",
    "\n",
    "**log_level**: Global codecarbon log level (by order of verbosity): “debug”, “info” (defaults), “warning”,\n",
    "“error”, or “critical”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4da26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_emissions(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tracker = OfflineEmissionsTracker(country_iso_code='IRL', tracking_mode='machine', log_level='critical')\n",
    "        tracker.start()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        tracker.stop()\n",
    "        print(f\"\\nTraining time: {tracker.final_emissions_data.duration:.4f} seconds\")\n",
    "        print(f\"GHG emissions: {np.format_float_scientific(tracker.final_emissions_data.emissions, precision=2)} kg CO2e\")\n",
    "        print(f\"Electricity: {np.format_float_scientific(tracker.final_emissions_data.energy_consumed, precision=2)} kWh\\n\")\n",
    "\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a7d26",
   "metadata": {},
   "source": [
    "### Now assess carbon emissions with your decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7cff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:39:02] offline tracker init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 22.5460 seconds\n",
      "GHG emissions: 3.06e-05 kg CO2e\n",
      "Electricity: 8.41e-05 kWh\n",
      "\n",
      "100000000\n",
      "\n",
      "Training time: 8.6249 seconds\n",
      "GHG emissions: 1.17e-05 kg CO2e\n",
      "Electricity: 3.22e-05 kWh\n",
      "\n",
      "100000000\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def while_loop(n):\n",
    "    i = 0\n",
    "    s = 0\n",
    "    while i < n:\n",
    "        s += 1\n",
    "        i += 1\n",
    "    return s\n",
    "\n",
    "@track_emissions\n",
    "def for_loop(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += 1\n",
    "    return s\n",
    "\n",
    "print(while_loop(numb))\n",
    "print(for_loop(numb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5df99283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum range\n",
      "Training time: 4.8830 seconds\n",
      "GHG emissions: 6.62e-06 kg CO2e\n",
      "Electricity: 1.82e-05 kWh\n",
      "\n",
      "Sum numpy\n",
      "Training time: 0.3488 seconds\n",
      "GHG emissions: 4.73e-07 kg CO2e\n",
      "Electricity: 1.30e-06 kWh\n",
      "\n",
      "Sum math\n",
      "Training time: 0.0000 seconds\n",
      "GHG emissions: 0.e+00 kg CO2e\n",
      "Electricity: 0.e+00 kWh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\anaconda3\\Lib\\site-packages\\codecarbon\\emissions_tracker.py:599: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  emissions_rate=emissions / duration.seconds,  # kg/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4999999950000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@track_emissions\n",
    "def sum_range(n):\n",
    "    return sum(range(n))\n",
    "\n",
    "@track_emissions\n",
    "def sum_numpy(n):\n",
    "    return np.sum(np.arange(n))\n",
    "\n",
    "@track_emissions\n",
    "def sum_math(n):\n",
    "    return (n * (n-1)) // 2\n",
    "\n",
    "print(\"Sum range\")\n",
    "sum_range(numb)\n",
    "print(\"\\nSum numpy\")\n",
    "sum_numpy(numb)\n",
    "print(\"\\nSum math\")\n",
    "sum_math(numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a2792",
   "metadata": {},
   "source": [
    "# Data scientist example: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c33990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset\n",
    "np.random.seed(18)\n",
    "X = 2 * np.random.rand(1000000, 1)\n",
    "y = 4 + 3 * X + np.random.randn(1000000, 1)\n",
    "\n",
    "# Division of the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5faba718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9961\n",
      "Training time: 0.1217 seconds\n",
      "GHG emissions: 1.64e-07 kg CO2e\n",
      "Electricity: 4.50e-07 kWh\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def lin_reg():\n",
    "    # Init and training\n",
    "    model = LinearRegression()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    \n",
    "lin_reg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfa950",
   "metadata": {},
   "source": [
    "**Use of batches**: Instead of training the model on all the data at once, we do it in small batches, which can be more efficient in terms of memory management and resource consumption.\n",
    "\n",
    "**Reduce redundancy**: Training the model with batches can sometimes require less training time overall and therefore consume less energy, but this depends on the context and available resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e93825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9961387755087499\n",
      "Training time: 0.0370 seconds\n",
      "GHG emissions: 5.02e-08 kg CO2e\n",
      "Electricity: 1.38e-07 kWh\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def opti_lin_reg():\n",
    "    # Use of batches for training\n",
    "    batch_size = 50000\n",
    "    model = LinearRegression()\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        end = i + batch_size\n",
    "        model.fit(X_train[i:end], y_train[i:end])\n",
    "\n",
    "    # Predictions and evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "opti_lin_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e305fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain (% of time):\n",
      "-69.59737058340181\n"
     ]
    }
   ],
   "source": [
    "non_opti = 0.1217\n",
    "opti = 0.0370\n",
    "\n",
    "print(\"Gain (% of time):\")\n",
    "print(-100 + (opti * 100 / non_opti))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc0d81",
   "metadata": {},
   "source": [
    "# Training computer vision models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30f2a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56bf4d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 images belonging to 7 classes.\n",
      "Found 18 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an ImageDataGenerator object\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)  # rescale pixel values to [0, 1]\n",
    "\n",
    "# Load images from directory\n",
    "batch_size = 32\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "data_dir = 'Images'\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0a2c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 10s/step - accuracy: 0.1455 - loss: 2.9550 - val_accuracy: 0.2222 - val_loss: 1.9416\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 10s/step - accuracy: 0.0766 - loss: 3.1694 - val_accuracy: 0.2222 - val_loss: 1.9367\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8s/step - accuracy: 0.1462 - loss: 3.1813 - val_accuracy: 0.2222 - val_loss: 1.9232\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9s/step - accuracy: 0.1529 - loss: 3.4597 - val_accuracy: 0.2222 - val_loss: 1.9188\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9s/step - accuracy: 0.2616 - loss: 3.6816 - val_accuracy: 0.2222 - val_loss: 1.9075\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 10s/step - accuracy: 0.4483 - loss: 2.6025 - val_accuracy: 0.2222 - val_loss: 1.9009\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12s/step - accuracy: 0.4539 - loss: 3.0921 - val_accuracy: 0.2222 - val_loss: 1.9089\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 10s/step - accuracy: 0.6691 - loss: 1.4690 - val_accuracy: 0.2222 - val_loss: 1.9069\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 12s/step - accuracy: 0.5433 - loss: 1.8623 - val_accuracy: 0.2222 - val_loss: 1.9129\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11s/step - accuracy: 0.7331 - loss: 1.4552 - val_accuracy: 0.2222 - val_loss: 1.9251\n",
      "Training time: 384.5409 seconds\n",
      "GHG emissions: 5.22e-04 kg CO2e\n",
      "Electricity: 1.43e-03 kWh\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def vision():\n",
    "    # Define model\n",
    "    model = ResNet50(weights=None, input_shape=(32, 32, 3), classes=7)\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train\n",
    "    model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "    \n",
    "vision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd6b42",
   "metadata": {},
   "source": [
    "**Optimizations:**\n",
    "- Mixed precision training: Enables mixed precision training, which allows the model to use 16-bit floating-point numbers instead of the standard 32-bit. Using 16-bit numbers can reduce memory usage and potentially improve the training speed.\n",
    "- Pre-trained model: Leverage knowledge from a large dataset to improve performance.\n",
    "- Classification head: Fine-tune the model for the specific task.\n",
    "- Freezing base model: Freezing the base model means that its weights will not be updated during training. This can be power efficient because it reduces the computational load, as the pre-trained weights are kept fixed.\n",
    "- Appropriate loss and metrics: Specify the optimizer, loss function, and metrics. While not directly related to power efficiency, using appropriate optimizers and loss functions can indirectly affect training efficiency.\n",
    "\n",
    "    **Other ideas (not in this example):**\n",
    "- Lower resolution: Reduce compute and prevent overfitting.\n",
    "- Smaller batch size: Reduce memory usage.\n",
    "- Early stopping: Avoid unnecessary computations.\n",
    "- Reduce epochs: Reduce compute.\n",
    "- Optimize data loading: Speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8823f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - accuracy: 0.0827 - loss: 3.8242 - val_accuracy: 0.1111 - val_loss: 3.9134\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 550ms/step - accuracy: 0.1439 - loss: 3.3571 - val_accuracy: 0.2222 - val_loss: 2.4054\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 537ms/step - accuracy: 0.1844 - loss: 2.2664 - val_accuracy: 0.2222 - val_loss: 1.9072\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 524ms/step - accuracy: 0.2166 - loss: 2.0508 - val_accuracy: 0.2222 - val_loss: 2.1127\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 754ms/step - accuracy: 0.1604 - loss: 2.1957 - val_accuracy: 0.2222 - val_loss: 2.1546\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 500ms/step - accuracy: 0.2314 - loss: 2.1780 - val_accuracy: 0.2222 - val_loss: 2.0696\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 501ms/step - accuracy: 0.2130 - loss: 1.9763 - val_accuracy: 0.2778 - val_loss: 1.9793\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 569ms/step - accuracy: 0.1957 - loss: 2.0166 - val_accuracy: 0.2222 - val_loss: 1.9220\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 534ms/step - accuracy: 0.2072 - loss: 1.9517 - val_accuracy: 0.2778 - val_loss: 1.8823\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 532ms/step - accuracy: 0.1838 - loss: 1.9468 - val_accuracy: 0.2778 - val_loss: 1.8633\n",
      "Training time: 70.3510 seconds\n",
      "GHG emissions: 9.54e-05 kg CO2e\n",
      "Electricity: 2.62e-04 kWh\n"
     ]
    }
   ],
   "source": [
    "@track_emissions\n",
    "def opti_vision():\n",
    "    # Enable mixed precision training\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "    # Load a pre-trained model\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add a classification head\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(7)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[SparseCategoricalAccuracy(name='accuracy')])\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "opti_vision()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf9ed5",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "LSTM models are a type of recurrent neural network (RNN) that are particularly well-suited for time series data and sequence prediction problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f75d208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1849\n",
      "Epoch 2/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0831\n",
      "Epoch 3/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0827\n",
      "Epoch 4/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0835\n",
      "Epoch 5/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0823\n",
      "Epoch 6/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0826\n",
      "Epoch 7/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0807\n",
      "Epoch 8/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0814\n",
      "Epoch 9/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0802\n",
      "Epoch 10/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0783\n",
      "Epoch 11/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0833\n",
      "Epoch 12/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0787\n",
      "Epoch 13/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0862\n",
      "Epoch 14/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0827\n",
      "Epoch 15/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0846\n",
      "Epoch 16/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0789\n",
      "Epoch 17/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0836\n",
      "Epoch 18/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0793\n",
      "Epoch 19/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0832\n",
      "Epoch 20/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0805\n",
      "Training time: 10.2938 seconds\n",
      "GHG emissions: 1.4e-05 kg CO2e\n",
      "Electricity: 3.84e-05 kWh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic data\n",
    "x_train = np.random.rand(1000, 10, 1)\n",
    "y_train = np.random.rand(1000, 1)\n",
    "\n",
    "@track_emissions\n",
    "def lstm():\n",
    "    # Define model\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(10, 1)),\n",
    "        LSTM(50),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32)\n",
    "    \n",
    "lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcddaa",
   "metadata": {},
   "source": [
    "**Optimizations**\n",
    "- Mixed precision training: Enables mixed precision training, which allows the model to use 16-bit floating-point numbers instead of the standard 32-bit. Using 16-bit numbers can reduce memory usage and potentially improve the training speed.\n",
    "- Callbacks for optimization: EarlyStopping and ReduceLROnPlateau callbacks are used to stop training prematurely if the validation loss stops decreasing and to reduce the learning rate when the validation loss stops decreasing, respectively. This can help save energy by avoiding excessive model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "29a670e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z478SG\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: 0.1628 - val_loss: 0.0914 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0919 - val_loss: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0906 - val_loss: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0864 - val_loss: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0900 - val_loss: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0901 - val_loss: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0857 - val_loss: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0893 - val_loss: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0882 - val_loss: 0.0823 - learning_rate: 0.0010\n",
      "Training time: 7.6934 seconds\n",
      "GHG emissions: 1.04e-05 kg CO2e\n",
      "Electricity: 2.87e-05 kWh\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Activate mixed precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Generate synthetic data\n",
    "x_train = np.random.rand(1000, 10, 1)\n",
    "y_train = np.random.rand(1000, 1)\n",
    "\n",
    "@track_emissions\n",
    "def lstm_opti():\n",
    "    # Define model\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(10, 1)),\n",
    "        LSTM(50),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Callbacks for optimization\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "    # Training the model with callbacks\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "lstm_opti()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb763a",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431563f",
   "metadata": {},
   "source": [
    "Improving the power computation efficiency of an SQL request involves optimizing the query and the database management system. Here are some key strategies:\n",
    "\n",
    "1. Indexing: Properly indexing the tables can significantly improve query performance by reducing the amount of data that needs to be scanned.\n",
    "\n",
    "2. Database Schema Design: Designing an efficient database schema, including normalization and denormalization where appropriate.\n",
    "\n",
    "Other ways of optimizing exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dac1e2",
   "metadata": {},
   "source": [
    "# Evaluate the environmental impact of one of your projects!\n",
    "You can use one of the libraries listed above in your projects, then try to reduce the environmental impact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
